{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "from shutil import copyfile, move\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " from mplfinance.original_flavor import candlestick_ohlc,volume_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python run_binary_preprocessing.py \n",
    "def isnan(value):\n",
    "    try:\n",
    "        import math\n",
    "        return math.isnan(float(value))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def removeOutput(finput):\n",
    "    if(Path(finput)).is_file():\n",
    "        os.remove(finput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countImage(input):\n",
    "    num_file = sum([len(files) for r, d, files in os.walk(input)])\n",
    "    num_dir = sum([len(d) for r, d, files in os.walk(input)])\n",
    "    print(\"num of files : {}\\nnum of dir : {}\".format(num_file, num_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(fname,seq_len):\n",
    "    print('Creating label ...')\n",
    "    filename=fname.split('/')\n",
    "    #데이터가 없데이트될 경우를 대비해 기존에 만든 레이블데이터를 삭제\n",
    "    removeOutput(\"{}_label_{}.txt\".format(filename[1][:-4],seq_len))\n",
    "    \n",
    "    #개별 종목 데이터 읽어오기\n",
    "    df = pd.read_csv(fname,parse_dates=True,index_col=0)\n",
    "    df.fillna(0)\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    df['Date'] = df['Date'].map(mdates.date2num)\n",
    "    for i in range(0,len(df)):\n",
    "        # ix: 인덱스 접근자 iloc인덱서와 유사\n",
    "        # seq_len 단위로 데이터프레임을 슬라이싱해 기간별 레이블링 작업 준비\n",
    "        c = df.ix[i:i+int(seq_len),:]\n",
    "        \n",
    "        starting = 0\n",
    "        endvalue = 0\n",
    "        label = ''\n",
    "        #레이블링 작업을 위해 +1\n",
    "        if len(c) == int(seq_len)+1:\n",
    "            starting = c['Open'].iloc[-1]\n",
    "            value = c['Close'].iloc[-1]\n",
    "            tmp_rtn = endvalue / starting - 1\n",
    "            if tmp_rtn > 0:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "                \n",
    "            with open('{}_label_{}.txt'.format(filename[1][:-4],seq_len),'a') as the_file:\n",
    "                #데이터 구간별 레이블을 저장하기 위해 텍스트파일에 덮어쓰기\n",
    "                the_file.write('{}-{},{}'.format(filename[1][-4],i,label))\n",
    "                the_file.write('\\n')\n",
    "                \n",
    "    print(\"Create label finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohcl2cs(fname,seq_len,dataset_type,dimension,use_volume):\n",
    "    print(\"Converting ohlc to candlestick\")\n",
    "    symbol = fname.split('_')[0]\n",
    "    symbol = symbol.split('/')[1]\n",
    "    print(symbol)\n",
    "    path = \"{}\".format(os.getcwd())\n",
    "    #캔들차트 데이터를 저장할 디렉토리 생성\n",
    "    if not os.path.exists(\"{}/dataset/{}_{}/{}/{}\".format(path,seq_len,dimension,symbol,dataset_type)):\n",
    "        os.makedirs(\"{}/dataset/{}_{}/{}/{}\".format(path,seq_len,dimension,symbol,dataset_type))\n",
    "        \n",
    "    df = pd.read_csv(fname,parse_date=True,index_col=0)\n",
    "    df.fillna(0)\n",
    "    plt.style.use('dark_background')\n",
    "    df.reset_index(inplace=True)\n",
    "    df['Date'] = df['Date'].map(mdates.date2num)\n",
    "    # 마지막 일수 미만인 경우를 제외하기 위해 입력 일자 간격만큼 뒤에서 빼기\n",
    "    for i in range(0,len(df)-int(seq_len)):\n",
    "        # ohlc + volume\n",
    "        # 소스데이터 불러오기\n",
    "        c = df.ix[i:i+int(seq_len)-1,:]\n",
    "        if len(c) == int(seq_len):\n",
    "            my_dpi = 96\n",
    "            fig = plt.figure(figsize=(dimension/my_dpi,dimension/my_dpi),dpi=my_dpi)\n",
    "            ax1 = fig.add_subplot(1,1,1)\n",
    "            candlestick_ohlc(ax1,c['Open'],c['Close'],c['High'],c['Low'],width=1,colorup='#77d879',colordown='#db3f3f')\n",
    "            ax1.grid(False)\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "            ax1.xaxis.set_visible(False)\n",
    "            ax1.yaxis.set_visible(False)\n",
    "            ax1.axis('off')\n",
    "            # 거래량 데이터 사용여부\n",
    "            if use_volume:\n",
    "                ax2 = ax1.tiwnx()\n",
    "                bc = volume_overlay(ax2,c['Open'],c['Close'],c['High'],c['Low'],width=1,colorup='#77d879',colordown='#db3f3f',alpha=0.5)\n",
    "                ax2.add_collection(bc)\n",
    "                ax2.grid(False)\n",
    "                ax2.set_xticklabels([])\n",
    "                ax2.set_yticklabels([])\n",
    "                ax2.xaxis.set_visible(False)\n",
    "                ax2.yaxis.set_visible(False)\n",
    "                ax2.axis('off')\n",
    "        pngfile = 'dataset/{}_{}/{}/{}/{}-{}.png',format(seq_len,dimension,symbol,dataset_type,fname[11:-4],i)\n",
    "        fig.savefig(pngfile,pad_inches=0,transparent=False)\n",
    "        plt.close(fig)\n",
    "        \n",
    "    print('Converting olhc to candlestick finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_dataset(input,label_file):\n",
    "    label_dict = {}\n",
    "    # create_label에서 만든 레이블 데이터 읽어오기\n",
    "    with open(label_file) as f:\n",
    "        for line in f:\n",
    "            (key,val) = line.split(',')\n",
    "            label_dict[key] = val.rstrip()\n",
    "            \n",
    "    path = \"{}/{}\".format(os.getcwd(),input)\n",
    "    for filename in os.lostdir(path):\n",
    "        if filename is not'':\n",
    "            for k,v in label_dict.items():\n",
    "                splitname = filename.split('_')\n",
    "                f,e = os.path.splitext(filename)\n",
    "                newname = \"{}_{}\".format(splitname[0],splitname[1])\n",
    "                if newname == k:\n",
    "                    new_name = \"{}-{}.png\".format(v,f)\n",
    "                    os.rename(\"{}/{}\".format(path,filename),\"{}/{}\".format(path,new_name))\n",
    "                    break\n",
    "                    \n",
    "    folders = ['1','0']\n",
    "    for folder in folders:\n",
    "        #캔들차트 이미지 분류를 위한 디렉토리 생성\n",
    "        if not os.path.exists(\"{}/classes/{}\".format(path,folder)):\n",
    "            os.makedirs(\"{}/classes/{}\".format(path,folder))\n",
    "     \n",
    "    # path경로에 있는 파일을 찾는다. 파일을 찾아 특정 디렉토리를 제외한 모든 캔들차트 파일은 레이블 폴더로 옮긴다.\n",
    "    for filename in os.listdir(path):\n",
    "        if filename is not '' and filename is not 'classes':\n",
    "            f,e = os.path.splitext(filename)\n",
    "            #레이블이 1인 경우에 해당되는 디렉토리에 옮김\n",
    "            if label_dict[f] == \"1\":\n",
    "                move(\"{}/{}\".format(path,filename),\"{}/classes/1/{}\".format(path,filename))\n",
    "            #레이블이 0인 경우에 해당되는 디렉토리에 옮김\n",
    "            elif label_dict[f] == \"0\":\n",
    "                move(\"{}/{}\".format(path,filename),\"{}/clases/0/{}\".format(path,filename))\n",
    "            \n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python generatedata.py\n",
    "counttest = 0\n",
    "counttrain = 0\n",
    "# os.walk() 이용하여 현재 디렉터리 파일과 하위 디렉터리를 순차적으로 순회\n",
    "for root,dirs,files in os.walk(\"{}/{}\".format(pathdir,origindir)):\n",
    "    for file in files:\n",
    "        tmp = root.replace('\\\\','/')\n",
    "        tmp_label = tmp.split('/')[-1]\n",
    "        \n",
    "        if tmp_label=='0':\n",
    "            if 'test' in file:\n",
    "                origin = \"{}/{}\".format(root,file)\n",
    "                destination = \"{}/{}/test/0/{}\".format(pathdir,targetdir,file)\n",
    "                copyfile(origin,destination)\n",
    "                counttest+=1\n",
    "            elif 'train' in file:\n",
    "                origin = \"{}/{}\".format(root,file)\n",
    "                destination = \"{}/{}/train/0/{}\".format(pathdir,targetdir,file)\n",
    "                copyfile(origin,destination)\n",
    "                counttrain+=1\n",
    "        elif tmp_label=='1':\n",
    "            if 'test' in file:\n",
    "                origin = \"{}/{}\".format(root,file)\n",
    "                destination = \"{}/{}/test/1/{}\".format(pathdir,targetdir,file)\n",
    "                copyfile(origin,destination)\n",
    "                counttest+=1\n",
    "            elif 'train' in file:\n",
    "                origin = \"{}/{}\".format(root,file)\n",
    "                destination = \"{}/{}/train/1/{}\".format(pathdir,targetdir,file)\n",
    "                copyfile(origin,destination)\n",
    "                counttrain+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python myDeepCNN.py \n",
    "def build_model(SHAPE,nb_classes,bn_axis,seed=None):\n",
    "    # 예측 결과값을 재현하기 위해 특정 시드값 설정\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    # 입력값을 전달받는 츨을 정의. 첫번째 입력값을 받을 때는 항상 입력데이터의 형태를 정의해야함\n",
    "    input_layer = Input(shape=SHAPE)\n",
    "    #Step 1\n",
    "    # 2차원 합성곱층 정의 앞에서 선언한 input_layer를 함수형으로 연결\n",
    "    x = Conv2D(32,3,3,init='glorot_uniform',border_mode='same',activation='relu')(input_layer)\n",
    "    \n",
    "    #Step 2 - Pooling\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    \n",
    "    #Step1\n",
    "    x = Conv2D(48,3,3,init='glorot_uniform',border_mode='same',activation='relu')(x)\n",
    "    \n",
    "    #Step2\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    # 과적합을 방지하기 위해 일부 연결층을 제거하는 드롭아웃층 추가\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    #Step 1\n",
    "    x = Conv2D(64,3,3,init='glorot_uniform',border_mode='same',activation='relu')(x)\n",
    "    \n",
    "    #Step 2\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    \n",
    "     #Step 1\n",
    "    x = Conv2D(96,3,3,init='glorot_uniform',border_mode='same',activation='relu')(x)\n",
    "    \n",
    "    #Step 2\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    #Step 3 - Flattening\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    #Step 4 - Full connection\n",
    "    x = Dense(output_dim=256,activation='relu')(x)\n",
    "    \n",
    "    #Dropout\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(output_dim=2,activation='softmax')(x)\n",
    "    \n",
    "    # 최종 연결된 출력층과 최초입력층을 전달해 모델 구축\n",
    "    model = Model(input_layer,x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=1.0e-4),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size=batch_size,epochs=epochs)\n",
    "model.save('{}epochs_{}batch_cnn_model_{}.h5'.format(epochs,batch_size,data_directory.replace(\"/\",\"_\")),overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)\n",
    "y_pred = np.argmax(predicted,axis=1)\n",
    "Y_test = np.argmax(Y_test,axis=1)\n",
    "cm = confusion_matrix(Y_test,y_pred)\n",
    "report = classification_report(Y_test,y_pred)\n",
    "tn = cm[0][0]\n",
    "fn = cm[1][0]\n",
    "tp = cm[1][1]\n",
    "fp = vm[0][1]\n",
    "if tp == 0:\n",
    "    tp=1\n",
    "if tn == 0:\n",
    "    tn=1\n",
    "if fp == 0:\n",
    "    fp=1\n",
    "if fn == 0:\n",
    "    fn=1\n",
    "    \n",
    "TPR = float(tp)/(float(tp)+float(fn))\n",
    "FPR = float(fp)/(float(fp)+float(tn))\n",
    "accracy = round(float(tp)+float(tn))/(float(tp)+float(fp)+float(fn)+float(tn),3)\n",
    "percitivity = round(float(tn)/(float(tn)+float(fp)),3)\n",
    "sensitivity = round(float(tp)/(float(tp)+float(fn)),3)\n",
    "mcc = round((float(tp)*float(tn)-float(fp)*float(fn))/math.sqrt((float(tp)+float(fp))*(float(tp)+float(fn))*(float(tn)+float(fp))*(float(tn)+float(fn))),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_binary_preprocessing.py \"BBNI.JK\" \"20\" \"50\"\n",
      "python generatedata.py \"dataset\" \"20_50/BBNI.JK\" \"dataset_BBNIJK_20_50\" \n",
      "python myDeepCNN.py \"-i\" \"dataset/dataset_BBNIJK_20_50\" \"-e\" \"50\" \"-d\" \"50\" \"-b\" \"8\" \"-o\" \"outputresult.txt\"\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "# python run_binary_preprocessing.py <ticker> <tradingdays> <windows> : 주가 데이터를 이미지 데이터로 변환 준비\n",
    "# python generatedata.py <pathdir> <origindir> <destinationdir> : 이미지 생성\n",
    "# python myDeepCNN.py -i <datasetdir> -e <number of epoch> -d <dimensionsize> -b <batchsize> -o <outputresult report> : 훈련\n",
    "try:\n",
    "    print(f'python run_binary_preprocessing.py \"BBNI.JK\" \"20\" \"50\"')\n",
    "    subprocess.call(f'python run_binary_preprocessing.py  \"BBNI.JK\" \"20\" \"50\" ', shell=True)\n",
    "\n",
    "    print(f'python generatedata.py \"dataset\" \"20_50/BBNI.JK\" \"dataset_BBNIJK_20_50\" ')\n",
    "    subprocess.call(f'python generatedata.py \"dataset\" \"20_50/BBNI.JK\" \"dataset_BBNIJK_20_50\" ', shell=True)\n",
    "\n",
    "    print(f'python myDeepCNN.py \"-i\" \"dataset/dataset_BBNIJK_20_50\" \"-e\" \"50\" \"-d\" \"50\" \"-b\" \"8\" \"-o\" \"outputresult.txt\"')\n",
    "    subprocess.call(f'python myDeepCNN.py \"-i\" \"dataset/dataset_BBNIJK_20_50\" \"-e\" \"50\" \"-d\" \"50\" \"-b\" \"8\" \"-o\" \"outputresult.txt\"', shell=True)\n",
    "except Exception as identifier:\n",
    "    print(identifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
